---
title: "Power and Sample Size Calculations"
date: "March 17th, 2016"
layout: post
output:
  html_document
tags: [R, stats]
---

Power calculations are always in the context of hypothesis testing where are interested in comparing the null hypothesis, <span class="inlinecode">$H_{0}$</span> to an alternative hypothesis <span class="inlinecode">$H_{A}$</span>. For instance, jk100

one might be interested in knowing whether the means of two groups of samples are the same are different:

<div>
$$\begin{align}
H_{0}: \mu_{1} = \mu_{2} \\
H_{1}: \mu_{1} \neq \mu_{2}
\end{align}$$
</div>






    + Null hypothesis and alternative hypothesis.
  * Need to define the crticial value. <span class="inlinecode">$alpha$</span>
* Alpha level: Probability of rejecting the null hypothesis assuming that the null hypothesis is true.
* Statistical power: Probability of rejecting the null hypothesis assuming that the alternative hypothesis is true. 
    + 1 - P(Type II error)
* Well-designed test will have high statistical power (e.g. 0.8 and 0.9)
    + We can increase power by increasing the effect size which is the difference between the parameter values of our null and alternative hypothesis
    + Increase sample size. This will reduce our standard error.
* To solve for power, we need 4 things:
    1. Alpha
        + one-sided or two sides
        + typically 0.05 or 0.01
    1. Sample size: Generally dependent on budget and logical constraints
    1. Effect size: Difference between the hypothesized parameter values
    1. Variance: Based on previous studies or pilot data.


    Sometimes the power is not something we get to selected as it is dicated by the funding agency
* We can solve the minimum detectable effect size.
* If we calculate power, then we have a specific sample-size.
* If we calculate sample-size, then we have a specific power we are interested.

Here is an overview of what will be discussed in this post.

**Table of Contents**

<ul data-toc="body" data-toc-headings="h2,h3"></ul>

```{r echo = FALSE}
library("knitr")
library("captioner")

tbl.nums <- captioner(prefix = "<u>Table</u>", css_class = "tblcaption")
```

## Power Analysis for Two-Sample T-tests

We can make use of the [pwr R package](https://cran.r-project.org/web/packages/pwr/index.html) to do some power calculations. For instance, we can use the `pwr.t2n.test` to do a power calculation for a two-sample t-test where the two groups have unequal sample sizes. For every test in this package, as long as we have 3 of the 4 following quantities we can calculate the missing quantity:

1. Sample size
1. Effect size
1. Significance level
1. Power

For instance, say we have two equal groups of samples (n = 100 samples in each group) and we are interested in detecting a significant difference (<span class="inlinecode">$\alpha = 0.05$</span>) between them with a power of 0.9. 

```{r, message = FALSE}
library("pwr")
library("broom")
library("dplyr")
library("ggplot2")

pwr.res.vals <- c("n1", "n2", "d", "sig.level", "power", "alternative")

pwr.t2n.test.res <- pwr.t2n.test(n1 = 100, n2 = 100, sig.level = 0.05, power = 0.9)
pwr.t2n.test.res.df <- 
  pwr.t2n.test.res[c(pwr.res.vals)] %>%
  as_data_frame()

kable(pwr.t2n.test.res.df)
```

Our minimum effect size here is `r pwr.t2n.test.res.df[["d"]]` meaning that we could detect an effect size of this magnitude with 90% power. Keep in mind, the effect size is with respect to the standard deviation here. So really in order for us to reject the null hypothesis, the difference in the two groups would have to be at least `r pwr.t2n.test.res.df[["d"]]` times the standard deviation. 

If we can increase our sample size say to 400 samples per group:

```{r}
pwr.t2n.test.res <- pwr.t2n.test(n1 = 400, n2 = 400, sig.level = 0.05, power = 0.9)
pwr.t2n.test.res.df <- 
  pwr.t2n.test.res[c(pwr.res.vals)] %>%
  as_data_frame()

kable(pwr.t2n.test.res.df)
```

Notice how or effect size drops down to `r pwr.t2n.test.res.df[["d"]]`. This makes sense because as we can get more samples we have the ability to detect smaller true differences more confidently. We can actually see how the effect size is affected as the sample increases.

```{r}
n.list <- seq(10, 1000, by = 5)
pwr.t2n.test.res.list <- NULL
for (i in 1:length(n.list)) {
  num.samples <- n.list[i]
  pwr.t2n.test.res.list[[i]] <- 
    pwr.t2n.test(n1 = num.samples, n2 = num.samples, sig.level = 0.05, 
                 power = 0.9)
}
pwr.t2n.test.res.list.df <- 
  bind_rows(pwr.t2n.test.res.list)

pwr.t2n.test.res.list.df %>%
  ggplot(aes(x = n1, y = d)) +
  geom_point() +
  geom_path(group = 1) +
  geom_hline(yintercept = 0.2, linetype = "dotted", col = "red") +
  geom_hline(yintercept = 0.5, linetype = "dotted", col = "red") +
  geom_hline(yintercept = 0.8, linetype = "dotted", col = "red") +
  xlab("Sample Size (Per Group)") +
  ylab("Effect Size") +
  annotate("text", x = 950, y = 0.25, label = "Small Effect") +
  annotate("text", x = 950, y = 0.55, label = "Medium Effect") +
  annotate("text", x = 950, y = 0.85, label = "Large Effect")
```

It is suggested (by Cohen) that the effect values of 0.2, 0.5, and 0.8 correspond to small, medium, and large effect sizes respectively. 

This if we had over 500 samples, we could detect an effect size as small as 0.2 and confidently say there is an actual difference between the two groups of samples.


Meaning that with less than 35 samples, we would require a fairly large effect size (> 0.8) in order to be able to reject the null hypothesis. Between 35 and 85 samples, we would require medium effect sizes (> 0.5). 

```{r}
library("DT")
pwr.t2n.test.res.list.df %>%
  select(-method) %>%
  datatable(style = "bootstrap",
            filter = "top")
```

## Biological Example



<div>
$$d = \frac{|\mu_{1}-\mu_{2}}{\sigma}$$
</div>


## References

* [Youtube - A conceptual introduction to power and sample size calculations using Stata](https://www.youtube.com/watch?v=QBONLUp7i28)
* [Effect Size for Independent Samples t-Test](http://www.statisticslectures.com/topics/effectsizeindependentsamplest/)
    + [Youtube video](https://www.youtube.com/watch?v=wGlbyNBxEM8)
* [Inference for Means: Comparing Two Independent Samples](http://www.stat.ubc.ca/~rollin/stats/ssize/n2.html)
* [Quick-R: Power Analysis](http://www.statmethods.net/stats/power.html)
* [idre - UCLA: Power Analysis for Two-group Independent sample t-test](http://www.ats.ucla.edu/stat/r/dae/t_test_power2.htm)
* [Calculating Power](https://www.youtube.com/watch?v=9lyCnLznAfs&nohtml5=False)

## R Session

```{r session, echo = FALSE}
devtools::session_info()
```
